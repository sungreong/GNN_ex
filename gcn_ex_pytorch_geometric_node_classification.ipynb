{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('rl': conda)"
  },
  "interpreter": {
   "hash": "4a34b7b2474f08d48dccc8848beb6384d8bb23eb99f2769807b9556af4c52f27"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def visualize(h, color):\n",
    "    z = TSNE(n_components=2).fit_transform(out.detach().cpu().numpy())\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nDataset: Cora():\n======================\nNumber of graphs: 1\nNumber of features: 1433\nNumber of classes: 7\n\nData(edge_index=[2, 10556], test_mask=[2708], train_mask=[2708], val_mask=[2708], x=[2708, 1433], y=[2708])\n===========================================================================================================\nNumber of nodes: 2708\nNumber of edges: 10556\nAverage node degree: 3.90\nNumber of training nodes: 140\nTraining node label rate: 0.05\nContains isolated nodes: False\nContains self-loops: False\nIs undirected: True\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n",
    "\n",
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('===========================================================================================================')\n",
    "\n",
    "# Gather some statistics about the graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "print(f'Contains isolated nodes: {data.contains_isolated_nodes()}')\n",
    "print(f'Contains self-loops: {data.contains_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([2568,  140])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.bincount(data.train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1433"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "dataset.num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([2708, 1433])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "data.x.shape ## flat 형으로 지정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([3, 4, 4,  ..., 3, 3, 3])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "data.y"
   ]
  },
  {
   "source": [
    "# Multi Layer Perceptron"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MLP(\n  (lin1): Linear(in_features=1433, out_features=16, bias=True)\n  (lin2): Linear(in_features=16, out_features=7, bias=True)\n)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(MLP, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.lin1 = Linear(dataset.num_features, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        return x\n",
    "\n",
    "model = MLP(hidden_channels=16)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Epoch: 001, Loss: 1.9615\n",
      "\u001b[KEpoch: 050, Loss: 1.0563\n",
      "Epoch: 051, Loss: 0.9893\n",
      "\u001b[KEpoch: 100, Loss: 0.5350\n",
      "Epoch: 101, Loss: 0.5343\n",
      "\u001b[KEpoch: 150, Loss: 0.4212\n",
      "Epoch: 151, Loss: 0.4128\n",
      "\u001b[KEpoch: 200, Loss: 0.3810\n",
      "Epoch: 201, Loss: 0.3768\n",
      "\u001b[KEpoch: 250, Loss: 0.3877\n",
      "Epoch: 251, Loss: 0.3709\n",
      "\u001b[KEpoch: 300, Loss: 0.3576\n",
      "Epoch: 301, Loss: 0.2698\n",
      "\u001b[KEpoch: 350, Loss: 0.3218\n",
      "Epoch: 351, Loss: 0.3197\n",
      "\u001b[KEpoch: 400, Loss: 0.3159\n",
      "Epoch: 401, Loss: 0.2577\n",
      "\u001b[KEpoch: 450, Loss: 0.3172\n",
      "Epoch: 451, Loss: 0.3502\n",
      "\u001b[KEpoch: 500, Loss: 0.3001\n",
      "Epoch: 501, Loss: 0.3243\n",
      "\u001b[KEpoch: 550, Loss: 0.2676\n",
      "Epoch: 551, Loss: 0.2728\n",
      "\u001b[KEpoch: 600, Loss: 0.2744\n",
      "Epoch: 601, Loss: 0.2704\n",
      "\u001b[KEpoch: 650, Loss: 0.3062\n",
      "Epoch: 651, Loss: 0.3000\n",
      "\u001b[KEpoch: 700, Loss: 0.2776\n",
      "Epoch: 701, Loss: 0.2793\n",
      "\u001b[KEpoch: 750, Loss: 0.2466\n",
      "Epoch: 751, Loss: 0.3197\n",
      "\u001b[KEpoch: 800, Loss: 0.2821\n",
      "Epoch: 801, Loss: 0.2931\n",
      "\u001b[KEpoch: 850, Loss: 0.2490\n",
      "Epoch: 851, Loss: 0.2614\n",
      "\u001b[KEpoch: 900, Loss: 0.2580\n",
      "Epoch: 901, Loss: 0.2943\n",
      "\u001b[KEpoch: 950, Loss: 0.2643\n",
      "Epoch: 951, Loss: 0.2406\n",
      "\u001b[KEpoch: 1000, Loss: 0.2786"
     ]
    }
   ],
   "source": [
    "from IPython.display import Javascript  # Restrict height of output cell.\n",
    "#display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
    "from IPython.display import HTML , clear_output\n",
    "model = MLP(hidden_channels=16)\n",
    "criterion = torch.nn.CrossEntropyLoss()  # Define loss criterion.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)  # Define optimizer.\n",
    "import sys\n",
    "\n",
    "class Printer():\n",
    "    \"\"\"Print things to stdout on one line dynamically\"\"\"\n",
    "    def __init__(self,num_period=10):\n",
    "        self.num_period = num_period\n",
    "        self.init_value = 0\n",
    "\n",
    "    def __call__(self,data) :\n",
    "        if self.init_value % self.num_period == 0 :\n",
    "            print('\\n'+data.__str__())\n",
    "            self.init_value = 1\n",
    "        else :\n",
    "            sys.stdout.write(\"\\r\\x1b[K\"+data.__str__())\n",
    "            sys.stdout.flush()\n",
    "            self.init_value += 1 \n",
    "\n",
    "printf = Printer(num_period=50)\n",
    "\n",
    "def train():\n",
    "      model.train()\n",
    "      optimizer.zero_grad()  # Clear gradients.\n",
    "      out = model(data.x)  # Perform a single forward pass.\n",
    "      loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "      loss.backward()  # Derive gradients.\n",
    "      optimizer.step()  # Update parameters based on gradients.\n",
    "      return loss\n",
    "\n",
    "def test():\n",
    "      model.eval()\n",
    "      out = model(data.x)\n",
    "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "      test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n",
    "      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n",
    "      return test_acc\n",
    "\n",
    "for epoch in range(1, 1001):\n",
    "    loss = train()\n",
    "    printf(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Progress: |##################################################| 100.0% Complete\n"
     ]
    }
   ],
   "source": [
    "def progressBar(iterable, prefix = '', suffix = '', decimals = 1, length = 100, fill = '█', printEnd = \"\\r\"):\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "        printEnd    - Optional  : end character (e.g. \"\\r\", \"\\r\\n\") (Str)\n",
    "    \"\"\"\n",
    "    total = len(iterable)\n",
    "    # Progress Bar Printing Function\n",
    "    def printProgressBar (iteration):\n",
    "        percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "        filledLength = int(length * iteration // total)\n",
    "        bar = fill * filledLength + '-' * (length - filledLength)\n",
    "        print(f'\\r{prefix} |{bar}| {percent}% {suffix}', end = printEnd)\n",
    "    # Initial Call\n",
    "    printProgressBar(0)\n",
    "    # Update Progress Bar\n",
    "    for i, item in enumerate(iterable):\n",
    "        yield item\n",
    "        printProgressBar(i + 1)\n",
    "    # Print New Line on Complete\n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "# A List of Items\n",
    "items = list(range(0, 57))\n",
    "l = len(items)\n",
    "\n",
    "for item in progressBar(items, prefix = 'Progress:', suffix = 'Complete', length = 50,fill=\"#\"):\n",
    "    # Do stuff...\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=16)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'GCN' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-556fceddd98e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GCN' is not defined"
     ]
    }
   ],
   "source": [
    "model = GCN(hidden_channels=16)\n",
    "model.eval()\n",
    "\n",
    "out = model(data.x, data.edge_index)\n",
    "visualize(out, color=data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Javascript  # Restrict height of output cell.\n",
    "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
    "\n",
    "model = GCN(hidden_channels=16)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "      model.train()\n",
    "      optimizer.zero_grad()  # Clear gradients.\n",
    "      out = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "      loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "      loss.backward()  # Derive gradients.\n",
    "      optimizer.step()  # Update parameters based on gradients.\n",
    "      return loss\n",
    "\n",
    "def test():\n",
    "      model.eval()\n",
    "      out = model(data.x, data.edge_index)\n",
    "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "      test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n",
    "      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n",
    "      return test_acc\n",
    "\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
   ]
  }
 ]
}