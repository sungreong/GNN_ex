{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def leaky_relu(z):\n",
    "    return np.where(z > 0, z, z * 0.01)\n",
    "\n",
    "def softmax(z):\n",
    "    if len(z.shape) > 1:\n",
    "        # Softmax for matrix\n",
    "        max_matrix = np.max(z, axis=0)\n",
    "        stable_z = z - max_matrix\n",
    "        e = np.exp(stable_z)\n",
    "        a = e / np.sum(e, axis=0, keepdims=True)\n",
    "    else:\n",
    "        # Softmax for vector\n",
    "        vector_max_value = np.max(z)\n",
    "        a = (np.exp(z - vector_max_value)) / sum(np.exp(z - vector_max_value))\n",
    "\n",
    "    assert a.shape == z.shape\n",
    "\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('\\n\\n----- One-hot vector representation of nodes. Shape(n,n)\\n')\n",
    "X = np.eye(5, 5)\n",
    "n = X.shape[0]\n",
    "np.random.shuffle(X)\n",
    "print(X)\n",
    "\n",
    "print('\\n\\n----- Embedding dimension\\n')\n",
    "emb = 3\n",
    "print(emb)\n",
    "\n",
    "print('\\n\\n----- Weight Matrix. Shape(emb, n)\\n')\n",
    "W = np.random.uniform(-np.sqrt(1. / emb), np.sqrt(1. / emb), (emb, n))\n",
    "print(W)\n",
    "\n",
    "print('\\n\\n----- Adjacency Matrix (undirected graph). Shape(n,n)\\n')\n",
    "A = np.random.randint(2, size=(n, n))\n",
    "np.fill_diagonal(A, 1)  \n",
    "A = (A + A.T)\n",
    "A[A > 1] = 1\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----- Linear Transformation. Shape(n, emb)\n",
      "\n",
      "[[-0.16565732 -0.01631104  0.08638784]\n",
      " [ 0.44534168  0.51071103  0.21891362]\n",
      " [-0.37986297 -0.00899712 -0.23351036]\n",
      " [-0.06611432 -0.22554181  0.46799425]\n",
      " [ 0.17553066 -0.06967223  0.43153729]]\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\n----- Linear Transformation. Shape(n, emb)\\n')\n",
    "z1 = X.dot(W.T)\n",
    "print(z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----- Concat hidden features to represent edges. Shape(len(emb.concat(emb)), number of edges)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# equation (2) - First part\n",
    "print('\\n\\n----- Concat hidden features to represent edges. Shape(len(emb.concat(emb)), number of edges)\\n')\n",
    "edge_coords = np.where(A==1)\n",
    "h_src_nodes = z1[edge_coords[0]]\n",
    "h_dst_nodes = z1[edge_coords[1]]\n",
    "z2 = np.concatenate((h_src_nodes, h_dst_nodes), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.16565732, -0.01631104,  0.08638784],\n",
       "       [-0.16565732, -0.01631104,  0.08638784],\n",
       "       [-0.16565732, -0.01631104,  0.08638784],\n",
       "       [-0.16565732, -0.01631104,  0.08638784],\n",
       "       [ 0.44534168,  0.51071103,  0.21891362],\n",
       "       [ 0.44534168,  0.51071103,  0.21891362],\n",
       "       [ 0.44534168,  0.51071103,  0.21891362],\n",
       "       [ 0.44534168,  0.51071103,  0.21891362],\n",
       "       [-0.37986297, -0.00899712, -0.23351036],\n",
       "       [-0.37986297, -0.00899712, -0.23351036],\n",
       "       [-0.37986297, -0.00899712, -0.23351036],\n",
       "       [-0.37986297, -0.00899712, -0.23351036],\n",
       "       [-0.06611432, -0.22554181,  0.46799425],\n",
       "       [-0.06611432, -0.22554181,  0.46799425],\n",
       "       [-0.06611432, -0.22554181,  0.46799425],\n",
       "       [-0.06611432, -0.22554181,  0.46799425],\n",
       "       [ 0.17553066, -0.06967223,  0.43153729],\n",
       "       [ 0.17553066, -0.06967223,  0.43153729],\n",
       "       [ 0.17553066, -0.06967223,  0.43153729]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_src_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4]),\n",
       " array([0, 1, 2, 3, 0, 1, 2, 4, 0, 1, 2, 3, 0, 2, 3, 4, 1, 3, 4]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_src_nodes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_dst_nodes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.16565732 -0.01631104  0.08638784 -0.16565732 -0.01631104  0.08638784]\n",
      " [-0.16565732 -0.01631104  0.08638784  0.44534168  0.51071103  0.21891362]\n",
      " [-0.16565732 -0.01631104  0.08638784 -0.37986297 -0.00899712 -0.23351036]\n",
      " [-0.16565732 -0.01631104  0.08638784 -0.06611432 -0.22554181  0.46799425]\n",
      " [ 0.44534168  0.51071103  0.21891362 -0.16565732 -0.01631104  0.08638784]\n",
      " [ 0.44534168  0.51071103  0.21891362  0.44534168  0.51071103  0.21891362]\n",
      " [ 0.44534168  0.51071103  0.21891362 -0.37986297 -0.00899712 -0.23351036]\n",
      " [ 0.44534168  0.51071103  0.21891362  0.17553066 -0.06967223  0.43153729]\n",
      " [-0.37986297 -0.00899712 -0.23351036 -0.16565732 -0.01631104  0.08638784]\n",
      " [-0.37986297 -0.00899712 -0.23351036  0.44534168  0.51071103  0.21891362]\n",
      " [-0.37986297 -0.00899712 -0.23351036 -0.37986297 -0.00899712 -0.23351036]\n",
      " [-0.37986297 -0.00899712 -0.23351036 -0.06611432 -0.22554181  0.46799425]\n",
      " [-0.06611432 -0.22554181  0.46799425 -0.16565732 -0.01631104  0.08638784]\n",
      " [-0.06611432 -0.22554181  0.46799425 -0.37986297 -0.00899712 -0.23351036]\n",
      " [-0.06611432 -0.22554181  0.46799425 -0.06611432 -0.22554181  0.46799425]\n",
      " [-0.06611432 -0.22554181  0.46799425  0.17553066 -0.06967223  0.43153729]\n",
      " [ 0.17553066 -0.06967223  0.43153729  0.44534168  0.51071103  0.21891362]\n",
      " [ 0.17553066 -0.06967223  0.43153729 -0.06611432 -0.22554181  0.46799425]\n",
      " [ 0.17553066 -0.06967223  0.43153729  0.17553066 -0.06967223  0.43153729]]\n",
      "\n",
      "\n",
      "----- Attention coefficients. Shape(1, len(emb.concat(emb)))\n",
      "\n",
      "[[0.7893081  0.20043179 0.2323431  0.61813851 0.45226929 0.54239845]]\n",
      "\n",
      "\n",
      "----- Edge representations combined with the attention coefficients. Shape(1, number of edges)\n",
      "\n",
      "[[-0.17687181]\n",
      " [ 0.51104787]\n",
      " [-0.479485  ]\n",
      " [-0.00298638]\n",
      " [ 0.44181808]\n",
      " [ 1.12973775]\n",
      " [ 0.13920488]\n",
      " [ 0.8157944 ]\n",
      " [-0.41880626]\n",
      " [ 0.26911342]\n",
      " [-0.72141945]\n",
      " [-0.24492083]\n",
      " [-0.0515746 ]\n",
      " [-0.35418779]\n",
      " [ 0.12231083]\n",
      " [ 0.32240173]\n",
      " [ 0.84984812]\n",
      " [ 0.33581387]\n",
      " [ 0.53590476]]\n",
      "\n",
      "\n",
      "----- Leaky Relu. Shape(1, number of edges)\n",
      "[[-1.76871805e-03]\n",
      " [ 5.11047871e-01]\n",
      " [-4.79484996e-03]\n",
      " [-2.98637938e-05]\n",
      " [ 4.41818076e-01]\n",
      " [ 1.12973775e+00]\n",
      " [ 1.39204885e-01]\n",
      " [ 8.15794397e-01]\n",
      " [-4.18806260e-03]\n",
      " [ 2.69113416e-01]\n",
      " [-7.21419451e-03]\n",
      " [-2.44920834e-03]\n",
      " [-5.15745956e-04]\n",
      " [-3.54187787e-03]\n",
      " [ 1.22310830e-01]\n",
      " [ 3.22401726e-01]\n",
      " [ 8.49848116e-01]\n",
      " [ 3.35813865e-01]\n",
      " [ 5.35904761e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Concatenation tests\n",
    "assert len(edge_coords[1]) == z2.shape[0], \"The number of edges in A is not equal to the number of concat edges\"\n",
    "test_value = np.array([-0.11941829, -0.12942953, 0.19600584, 0.5029172, 0.3998854, -0.21561317])\n",
    "assert z2[4 ,:].tolist().sort()  == test_value.tolist().sort(), \"Something went wrong in the concat process\"\n",
    "print(z2)\n",
    "\n",
    "print('\\n\\n----- Attention coefficients. Shape(1, len(emb.concat(emb)))\\n')\n",
    "att = np.random.rand(1, z2.shape[1])\n",
    "print(att)\n",
    "\n",
    "print('\\n\\n----- Edge representations combined with the attention coefficients. Shape(1, number of edges)\\n')\n",
    "z2_att = z2.dot(att.T)\n",
    "print(z2_att)\n",
    "\n",
    "print('\\n\\n----- Leaky Relu. Shape(1, number of edges)')\n",
    "e = leaky_relu(z2_att)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.17687181]\n",
      " [ 0.51104787]\n",
      " [-0.479485  ]\n",
      " [-0.00298638]\n",
      " [ 0.19710452]\n",
      " [ 0.44181808]\n",
      " [ 1.12973775]\n",
      " [ 0.13920488]\n",
      " [ 0.6157035 ]\n",
      " [ 0.8157944 ]\n",
      " [-0.41880626]\n",
      " [ 0.26911342]\n",
      " [-0.72141945]\n",
      " [-0.24492083]\n",
      " [-0.04482994]\n",
      " [-0.0515746 ]\n",
      " [ 0.63634508]\n",
      " [-0.35418779]\n",
      " [ 0.12231083]\n",
      " [ 0.32240173]\n",
      " [ 0.16192844]\n",
      " [ 0.84984812]\n",
      " [-0.14068475]\n",
      " [ 0.33581387]\n",
      " [ 0.53590476]]\n",
      "\n",
      "\n",
      "----- Leaky Relu. Shape(1, number of edges)\n",
      "[[-1.76871805e-03]\n",
      " [ 5.11047871e-01]\n",
      " [-4.79484996e-03]\n",
      " [-2.98637938e-05]\n",
      " [ 1.97104516e-01]\n",
      " [ 4.41818076e-01]\n",
      " [ 1.12973775e+00]\n",
      " [ 1.39204885e-01]\n",
      " [ 6.15703502e-01]\n",
      " [ 8.15794397e-01]\n",
      " [-4.18806260e-03]\n",
      " [ 2.69113416e-01]\n",
      " [-7.21419451e-03]\n",
      " [-2.44920834e-03]\n",
      " [-4.48299385e-04]\n",
      " [-5.15745956e-04]\n",
      " [ 6.36345081e-01]\n",
      " [-3.54187787e-03]\n",
      " [ 1.22310830e-01]\n",
      " [ 3.22401726e-01]\n",
      " [ 1.61928440e-01]\n",
      " [ 8.49848116e-01]\n",
      " [-1.40684752e-03]\n",
      " [ 3.35813865e-01]\n",
      " [ 5.35904761e-01]]\n"
     ]
    }
   ],
   "source": [
    "# a_input = torch.cat([h.repeat(1, N).view(N * N, -1), h.repeat(N, 1)], dim=1).view(N, -1, 2 * out_features)a\n",
    "N = z1.shape[0]\n",
    "z2 = np.concatenate((np.repeat(z1,N,axis=0).reshape(N*N,-1) , np.tile(z1, (N,1))),axis=1)\n",
    "z2_att = z2.dot(att.T)\n",
    "print(z2_att)\n",
    "print('\\n\\n----- Leaky Relu. Shape(1, number of edges)')\n",
    "e = leaky_relu(z2_att)\n",
    "print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----- Edge scores as matrix. Shape(n,n)\n",
      "\n",
      "[[-1.76871805e-03  5.11047871e-01 -4.79484996e-03 -2.98637938e-05\n",
      "   0.00000000e+00]\n",
      " [ 4.41818076e-01  1.12973775e+00  1.39204885e-01  0.00000000e+00\n",
      "   8.15794397e-01]\n",
      " [-4.18806260e-03  2.69113416e-01 -7.21419451e-03 -2.44920834e-03\n",
      "   0.00000000e+00]\n",
      " [-5.15745956e-04  0.00000000e+00 -3.54187787e-03  1.22310830e-01\n",
      "   3.22401726e-01]\n",
      " [ 0.00000000e+00  8.49848116e-01  0.00000000e+00  3.35813865e-01\n",
      "   5.35904761e-01]]\n",
      "\n",
      "\n",
      "----- For each node, normalize the edge (or neighbor) contributions using softmax\n",
      "\n",
      "[0.21943665 0.34194517 0.2189064  0.21971177 0.19822137 0.36799682\n",
      " 0.15562511 0.27815671 0.24074799 0.27803595 0.24016624 0.24104983\n",
      " 0.2209045  0.2203707  0.24965281 0.30907199 0.4225795  0.25800654\n",
      " 0.31941396]\n",
      "\n",
      "\n",
      "----- Normalized edge score matrix. Shape(n,n)\n",
      "\n",
      "[[0.21943665 0.34194517 0.2189064  0.21971177 0.        ]\n",
      " [0.19822137 0.36799682 0.15562511 0.         0.27815671]\n",
      " [0.24074799 0.27803595 0.24016624 0.24104983 0.        ]\n",
      " [0.2209045  0.         0.2203707  0.24965281 0.30907199]\n",
      " [0.         0.4225795  0.         0.25800654 0.31941396]]\n"
     ]
    }
   ],
   "source": [
    "# equation (3)\n",
    "print('\\n\\n----- Edge scores as matrix. Shape(n,n)\\n')\n",
    "e_matr = np.zeros(A.shape)\n",
    "e_matr[edge_coords[0], edge_coords[1]] = e.reshape(-1,)\n",
    "print(e_matr)\n",
    "\n",
    "print('\\n\\n----- For each node, normalize the edge (or neighbor) contributions using softmax\\n')\n",
    "alpha0 = softmax(e_matr[:,0][e_matr[:,0] != 0]) \n",
    "alpha1 = softmax(e_matr[:,1][e_matr[:,1] != 0])\n",
    "alpha2 = softmax(e_matr[:,2][e_matr[:,2] != 0])\n",
    "alpha3 = softmax(e_matr[:,3][e_matr[:,3] != 0])\n",
    "alpha4 = softmax(e_matr[:,4][e_matr[:,4] != 0])\n",
    "alpha = np.concatenate((alpha0, alpha1, alpha2, alpha3, alpha4))\n",
    "print(alpha)\n",
    "\n",
    "print('\\n\\n----- Normalized edge score matrix. Shape(n,n)\\n')\n",
    "A_scaled = np.zeros(A.shape)\n",
    "A_scaled[edge_coords[0], edge_coords[1]] = alpha.reshape(-1,)\n",
    "print(A_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Neighborhood aggregation (GCN) scaled with attention scores (GAT). Shape(n, emb)\n",
      "\n",
      "[[ 0.01825062  0.11953221  0.14552005]\n",
      " [ 0.12075632  0.16392686  0.18137835]\n",
      " [-0.02322777  0.08154156  0.13839218]\n",
      " [-0.08255913 -0.08342676  0.21783679]\n",
      " [ 0.22720128  0.13537046  0.35109302]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# equation (4)\n",
    "print('\\n\\nNeighborhood aggregation (GCN) scaled with attention scores (GAT). Shape(n, emb)\\n')\n",
    "ND_GAT = A_scaled.dot(z1)\n",
    "print(ND_GAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation (1) is a linear transformation of the lower layer embedding $h_i^{(l)}$ and $W^{(l)}$ is its learnable weight matrix. This transformation is useful to achieve a sufficient expressive power to transform input features (in our example one-hot vectors) into high-level and dense features.\n",
    "Equation (2) computes a pair-wise un-normalized attention score between two neighbors. Here, it first concatenates the $z$ embeddings of the two nodes, where $||$ denotes concatenation, then takes a dot product of it and a learnable weight vector $\\vec a^{(l)}$, and applies a LeakyReLU in the end. This form of attention is usually called additive attention, contrast with the dot-product attention in the Transformer model. The attention score indicates the importance of a neighbor node in the message passing framework.\n",
    "Equation (3) applies a softmax to normalize the attention scores on each node’s incoming edges.\n",
    "Equation (4) is similar to GCN. The embeddings from neighbors are aggregated together, scaled by the attention scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3606dbd223bba5b3c8637604009e18334811217153b36ded1e4271889690306b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('gnn': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}